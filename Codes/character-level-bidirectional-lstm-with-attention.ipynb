{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "fo0C_nbLDbZW",
    "outputId": "9da4019a-7928-4a65-c853-5ac62ca6477e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval in e:\\anaconda\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in e:\\anaconda\\lib\\site-packages (from seqeval) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in e:\\anaconda\\lib\\site-packages (from seqeval) (1.20.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\anaconda\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in e:\\anaconda\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in e:\\anaconda\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'e:\\anaconda\\python.exe -m pip install --upgrade pip' command.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ctejk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install seqeval\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.keras import backend as K\n",
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import f1_score\n",
    "from seqeval.metrics import precision_score\n",
    "from seqeval.metrics import recall_score\n",
    "from seqeval.metrics import classification_report as seqeval_cs\n",
    "from sklearn.metrics import classification_report as sklearn_cs\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "QAKV4ntmDbZo",
    "outputId": "f8fd1cea-64cd-4bc7-88b0-f6fb584542b8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def _large_compatible_negative(tensor_type):\n",
    "  \"\"\"Large negative number as Tensor.\n",
    "  This function is necessary because the standard value for epsilon\n",
    "  in this module (-1e9) cannot be represented using tf.float16\n",
    "  Args:\n",
    "    tensor_type: a dtype to determine the type.\n",
    "  Returns:\n",
    "    a large negative number.\n",
    "  \"\"\"\n",
    "  if tensor_type == dtypes.float16:\n",
    "    return dtypes.float16.min\n",
    "  return -1e9\n",
    "\n",
    "class Softmax(tf.keras.layers.Layer):  \n",
    "# Softmax from TF 2.4.0, if you are already using TF 2.4.0, no need for this\n",
    "    def __init__(self, axis=-1, **kwargs):\n",
    "        super(Softmax, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            adder = (1.0 - math_ops.cast(mask, inputs.dtype)) * (\n",
    "                _large_compatible_negative(inputs.dtype))\n",
    "\n",
    "            inputs += adder\n",
    "        if isinstance(self.axis, (tuple, list)):\n",
    "            if len(self.axis) > 1:\n",
    "                return math_ops.exp(inputs - math_ops.reduce_logsumexp(\n",
    "                    inputs, axis=self.axis, keepdims=True))\n",
    "            else:\n",
    "                return K.softmax(inputs, axis=self.axis[0])\n",
    "        return K.softmax(inputs, axis=self.axis)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'axis': self.axis}\n",
    "        base_config = super(Softmax, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    @tf_utils.shape_type_conversion\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "def masked_softmax_cross_entropy_loss(y_true,y_pred): \n",
    "    masked_pred = tf.boolean_mask(y_pred,y_pred._keras_mask)\n",
    "    masked_true = tf.boolean_mask(y_true,y_pred._keras_mask)\n",
    "\n",
    "    loss = tf.math.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(masked_true,masked_pred))\n",
    "    return(loss)\n",
    "\n",
    "    \n",
    "def build_word_vocab(corpus,pad_index=0,pad_token=\"<PAD>\",unk_index=1,unk_token=\"<UNK>\"):  \n",
    "# Builds word level vocabulary dictionary from given corpus    \n",
    "\n",
    "  word_to_index = {}\n",
    "  index_to_word = {}\n",
    "  word_to_index[pad_token] = pad_index  \n",
    "  word_to_index[unk_token] = unk_index\n",
    "  index_to_word[pad_index] = pad_token\n",
    "  index_to_word[unk_index] = unk_token   \n",
    "  index = 0\n",
    "  if index == pad_index:\n",
    "    index += 1\n",
    "    if index == unk_index:\n",
    "      index += 1 \n",
    "  if index == unk_index:\n",
    "    index += 1\n",
    "    if index == pad_index:\n",
    "      index += 1 \n",
    "  for string in corpus:\n",
    "    # tokens = word_tokenize(str(string).lower())\n",
    "    tokens = string\n",
    "    for token in tokens:\n",
    "      if token not in word_to_index:      \n",
    "        word_to_index[token] = index\n",
    "        index_to_word[index] = token\n",
    "        index += 1\n",
    "        if index == pad_index:\n",
    "          index += 1\n",
    "          if index == unk_index:\n",
    "            index += 1 \n",
    "        if index == unk_index:\n",
    "          index += 1\n",
    "          if index == pad_index:\n",
    "            index += 1 \n",
    "  return word_to_index,index_to_word\n",
    "\n",
    "def build_char_vocab(corpus,pad_index=0,pad_token=\"<PAD>\",unk_index=1,unk_token=\"<UNK>\"):  \n",
    "# Builds character level vocabulary dictionary from given corpus      \n",
    "    \n",
    "    char_to_index = {}\n",
    "    index_to_char = {}\n",
    "    char_to_index[pad_token] = pad_index\n",
    "    char_to_index[unk_token] = unk_index    \n",
    "    index = 0\n",
    "    if index == pad_index:\n",
    "        index += 1\n",
    "        if index == unk_index:\n",
    "            index += 1 \n",
    "    if index == unk_index:\n",
    "        index += 1\n",
    "        if index == pad_index:\n",
    "            index += 1 \n",
    "    for string in corpus:\n",
    "        tokens = string\n",
    "        for token in tokens:\n",
    "              for char in token:\n",
    "                if char not in char_to_index:      \n",
    "                    char_to_index[char] = index\n",
    "                    index_to_char[index] = char\n",
    "                    index += 1\n",
    "                    if index == pad_index:\n",
    "                        index += 1\n",
    "                        if index == unk_index:\n",
    "                            index += 1 \n",
    "                    if index == unk_index:\n",
    "                        index += 1\n",
    "                        if index == pad_index:\n",
    "                            index += 1 \n",
    "    return char_to_index,index_to_char\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def to_padded_list_word(sentences,word_to_index,labels=[],pos=[],pad_cat=0,pad_token='<PAD>',\n",
    "                        unk_token='<UNK>',pos_pad=0,max_seq_len=1000):\n",
    "# Creates a 2d word level padded sequence from a given list of tokenized sentences. This also creates\n",
    "# masks to be propagated through the neural net. Masks are important to avoid processing the pads in \n",
    "# a padded sequence, and helps in stopping backprop loss from pads. This code is NOT optimized for \n",
    "# performance.\n",
    "    \n",
    "    seq_len = 0\n",
    "    for tokens in sentences:\n",
    "        if len(tokens) > seq_len:\n",
    "            seq_len = len(tokens)\n",
    "    # print(seq_len)\n",
    "    if max_seq_len < seq_len:\n",
    "        seq_len = max_seq_len\n",
    "\n",
    "    pad_index = word_to_index[pad_token]\n",
    "    unk_index = word_to_index[unk_token]\n",
    "    sents = []\n",
    "    labels_sents = []\n",
    "    pos_sents = []\n",
    "    mask_sents = []\n",
    "    p = 0\n",
    "    for tokens in sentences:\n",
    "        if len(tokens) < 0:\n",
    "            continue    \n",
    "        sent = []\n",
    "        labels_words = []\n",
    "        pos_words = []\n",
    "        mask_words = []\n",
    "        q = 0\n",
    "        for word in tokens:\n",
    "            try:    \n",
    "                sent.append(word_to_index[word])\n",
    "            except KeyError:\n",
    "                sent.append(unk_index)\n",
    "            if len(labels) > 0:\n",
    "                labels_words.append(labels[p][q])\n",
    "            if len(pos) > 0:\n",
    "                pos_words.append(pos[p][q])          \n",
    "            mask_words.append(True)\n",
    "            if len(sent) == seq_len:\n",
    "                sents.append(sent)\n",
    "                labels_sents.append(labels_words)\n",
    "                pos_sents.append(pos_words)\n",
    "                mask_sents.append(mask_words)\n",
    "                sent = []\n",
    "                labels_words = []\n",
    "                pos_words = []\n",
    "            q += 1\n",
    "        if len(sent) > 0:\n",
    "            pad_len = seq_len-len(sent)\n",
    "            sent.extend(pad_len*[pad_index])\n",
    "            labels_words.extend(pad_len*[pad_cat])\n",
    "            mask_words.extend(pad_len*[False])\n",
    "            pos_words.extend(pad_len*[pos_pad])\n",
    "            sents.append(sent)\n",
    "            labels_sents.append(labels_words)\n",
    "            mask_sents.append(mask_words)\n",
    "            pos_sents.append(pos_words)\n",
    "        p += 1  \n",
    "\n",
    "    return(sents,labels_sents,mask_sents,pos_sents)\n",
    "\n",
    "\n",
    "\n",
    "def to_padded_list_char(sentences,char_to_index,labels=[],pos=[],pad_cat=0,pad_token='<PAD>',\n",
    "                        unk_token='<UNK>',pos_pad=0,max_seq_len=1000,max_word_len=15): \n",
    "# Creates a 3d character level padded sequence from a given list of tokenized sentences. This also creates\n",
    "# masks to be propagated through the neural net. Masks are important to avoid processing the pads in \n",
    "# a padded sequence, and helps in stopping backprop loss from pads. This code is NOT optimized for \n",
    "# performance.\n",
    "        \n",
    "    seq_len = 0\n",
    "    for string in sentences:\n",
    "        if len(string) > seq_len:\n",
    "            seq_len = len(string)\n",
    "    if max_seq_len < seq_len:\n",
    "        seq_len = max_seq_len\n",
    "    max_len = []\n",
    "    pad_index = char_to_index[pad_token]\n",
    "    unk_index = char_to_index[unk_token]\n",
    "    sents = []\n",
    "    pos_sents = []\n",
    "    labels_sents = []\n",
    "    mask_sents = []\n",
    "    p = 0\n",
    "    for string in sentences:\n",
    "        sent_len = seq_len    \n",
    "        tokens = string\n",
    "        sent = []\n",
    "        pos_words = []\n",
    "        labels_words = []\n",
    "        mask_words = []\n",
    "        q = 0\n",
    "        for word in tokens:                      \n",
    "            word_char = []\n",
    "            for char in word:        \n",
    "                try:                      \n",
    "                    word_char.append(char_to_index[char])\n",
    "                except KeyError:\n",
    "                    word_char.append(unk_index) \n",
    "                if len(word_char) == max_word_len:\n",
    "                    sent.append(word_char)\n",
    "                    if len(labels) > 0:\n",
    "                        labels_words.append(labels[p][q])\n",
    "                    if len(pos) > 0:\n",
    "                        pos_words.append(pos[p][q])         \n",
    "                    mask_words.append(True)\n",
    "                    word_char = []\n",
    "            if len(sent) == seq_len:\n",
    "                sents.append(sent)\n",
    "                labels_sents.append(labels_words)\n",
    "                pos_sents.append(pos_words)\n",
    "                mask_sents.append(mask_words)\n",
    "                sent = []\n",
    "                labels_words = []\n",
    "                pos_words = []\n",
    "                mask_words = []\n",
    "            if len(word_char) > 0:\n",
    "                for i in range(max_word_len-len(word_char)):                      \n",
    "                    word_char.append(pad_index)\n",
    "                sent.append(word_char)\n",
    "                if len(labels) > 0:\n",
    "                    labels_words.append(labels[p][q])\n",
    "                if len(pos) > 0:\n",
    "                    pos_words.append(pos[p][q])        \n",
    "                mask_words.append(True)\n",
    "            q += 1\n",
    "\n",
    "        if len(sent) > 0:\n",
    "            sent_len = len(sent)\n",
    "            for i in range(seq_len-sent_len):\n",
    "                word_char = []\n",
    "                for j in range(max_word_len):\n",
    "                    word_char.append(pad_index)\n",
    "                sent.append(word_char)\n",
    "                labels_words.append(pad_cat)\n",
    "                pos_words.append(pos_pad)\n",
    "                mask_words.append(False)\n",
    "            sents.append(sent)\n",
    "            labels_sents.append(labels_words)            \n",
    "            pos_sents.append(pos_words)\n",
    "            mask_sents.append(mask_words)\n",
    "        p += 1  \n",
    "  \n",
    "    return(sents,labels_sents,mask_sents,pos_sents)\n",
    "\n",
    "def datagen_char(corpus,corpus_labels,corpus_pos,vocab,pad_cat,batch_size):\n",
    "# Creates a character based generator to fed to the neural network\n",
    "\n",
    "    df = pd.DataFrame({'sent':corpus})\n",
    "    df['labels'] = corpus_labels\n",
    "    df['pos'] = corpus_pos\n",
    "    while(1):\n",
    "        data = df.sample(frac = 1)\n",
    "        prev_index = 0\n",
    "        for index in range(batch_size,len(data),batch_size):\n",
    "            x = data.iloc[prev_index:index]['sent'] \n",
    "            y = data.iloc[prev_index:index]['labels'].to_list()\n",
    "            pos = data.iloc[prev_index:index]['pos'].to_list()\n",
    "            x,y,mask,pos = to_padded_list_char(x,vocab,y,pos,pad_cat)\n",
    "            yield ({'input_ids': np.array(x,dtype=np.float64),\n",
    "                    'attention_masks': np.array(mask),\n",
    "                    'pos_tags': np.array(pos,dtype=np.float64)},\n",
    "                   np.array(y,dtype=np.int32))\n",
    "            prev_index = index\n",
    "        if prev_index < len(data):\n",
    "            x = data.iloc[prev_index:len(data)]['sent']\n",
    "            y = data.iloc[prev_index:len(data)]['labels'].to_list()\n",
    "            pos = data.iloc[prev_index:len(data)]['pos'].to_list()\n",
    "            x,y,mask,pos = to_padded_list_char(x,vocab,y,pos,pad_cat)\n",
    "            yield ({'input_ids': np.array(x,dtype=np.float64),\n",
    "                    'attention_masks': np.array(mask),\n",
    "                    'pos_tags': np.array(pos,dtype=np.float64)},\n",
    "                   np.array(y,dtype=np.int32))\n",
    "\n",
    "\n",
    "def datagen_word(corpus,corpus_labels,corpus_pos,vocab,pad_cat,batch_size):\n",
    "# Creates a word based generator to fed to the neural network    \n",
    "\n",
    "    df = pd.DataFrame({'sent':corpus})\n",
    "    df['labels'] = corpus_labels\n",
    "    df['pos'] = corpus_pos\n",
    "    while(1):\n",
    "        data = df.sample(frac = 1)\n",
    "        prev_index = 0\n",
    "        for index in range(batch_size,len(data),batch_size):\n",
    "            x = data.iloc[prev_index:index]['sent'] \n",
    "            y = data.iloc[prev_index:index]['labels'].to_list()\n",
    "            pos = data.iloc[prev_index:index]['pos'].to_list()\n",
    "            x,y,mask,pos = to_padded_list_word(x,vocab,y,pos,pad_cat)\n",
    "            yield ({'input_ids': np.array(x,dtype=np.float64),\n",
    "                    'attention_masks': np.array(mask),\n",
    "                    'pos_tags': np.array(pos,dtype=np.float64)},\n",
    "                   np.array(y,dtype=np.int32))\n",
    "            prev_index = index\n",
    "        if prev_index < len(data):\n",
    "            x = data.iloc[prev_index:len(data)]['sent']\n",
    "            y = data.iloc[prev_index:len(data)]['labels'].to_list()\n",
    "            pos = data.iloc[prev_index:len(data)]['pos'].to_list()\n",
    "            x,y,mask,pos = to_padded_list_word(x,vocab,y,pos,pad_cat)\n",
    "            yield ({'input_ids': np.array(x,dtype=np.float64),\n",
    "                    'attention_masks': np.array(mask),\n",
    "                    'pos_tags': np.array(pos,dtype=np.float64)},\n",
    "                   np.array(y,dtype=np.int32))\n",
    "\n",
    "            \n",
    "def process_data(data_path,force_lowercase=False):\n",
    "# Data Processing borrowed from - \n",
    "# \"https://www.kaggle.com/abhishek/entity-extraction-model-using-bert-pytorch\"\n",
    "\n",
    "    df = pd.read_csv(data_path, encoding=\"latin-1\")\n",
    "    if force_lowercase:\n",
    "        df['Word'] = df['Word'].str.lower()\n",
    "    df.loc[:, \"Sentence #\"] = df[\"Sentence #\"].fillna(method=\"ffill\")\n",
    "\n",
    "    enc_pos = preprocessing.LabelEncoder()\n",
    "    enc_tag = preprocessing.LabelEncoder()\n",
    "\n",
    "    df.loc[:, \"POS\"] = enc_pos.fit_transform(df[\"POS\"])\n",
    "    df.loc[:, \"Tag\"] = enc_tag.fit_transform(df[\"Tag\"])\n",
    "\n",
    "\n",
    "    sentences = df.groupby(\"Sentence #\")[\"Word\"].apply(list).values\n",
    "    pos = df.groupby(\"Sentence #\")[\"POS\"].apply(list).values\n",
    "    tag = df.groupby(\"Sentence #\")[\"Tag\"].apply(list).values\n",
    "    return sentences, pos, tag, enc_pos, enc_tag\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition\n",
    "**Defining a Bidirectional LSTM Model with Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#MODEL\n",
    "            \n",
    "class label_init(tf.keras.initializers.Initializer):\n",
    "    def __call__(self,shape,dtype):\n",
    "        return( tf.eye(shape[0],shape[1],dtype=dtype))\n",
    "\n",
    "class sent_char_encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,vocab_dim,char_embed_size,word_embed_size):\n",
    "        super().__init__(name='sent_char_encoder')\n",
    "        self.embed = tf.keras.layers.Embedding(vocab_dim,char_embed_size,name='char_embeds')\n",
    "        self.conv = tf.keras.layers.Conv1D(word_embed_size,3,activation='relu',use_bias=False)\n",
    "        self.dense = tf.keras.layers.Dense(word_embed_size)\n",
    "    def call(self,x):\n",
    "        x = self.embed(x)\n",
    "        x = self.conv(x)\n",
    "        x = tf.math.reduce_max(x,axis=2)\n",
    "        return(self.dense(x))\n",
    "\n",
    "\n",
    "class BiLstm_attnv2(tf.keras.Model):\n",
    "    def __init__(self,vocab_dim,char_embed_size,word_embed_size,use_char_level_embeddings=True,\n",
    "                 lstm_hidden=8,num_classes=10,dropout=0.3,use_pos_features=False,num_pos=10):\n",
    "        super().__init__(name='BiLstm_attnv2')\n",
    "        self.num_classes = num_classes\n",
    "        if use_char_level_embeddings:\n",
    "            self.embed = sent_char_encoder(vocab_dim,char_embed_size,word_embed_size)\n",
    "        else:\n",
    "            self.embed = tf.keras.layers.Embedding(vocab_dim,word_embed_size,name='word_embeds')\n",
    "        if use_pos_features:\n",
    "            self.use_pos = True\n",
    "            self.pos_embed = tf.keras.layers.Embedding(num_pos,num_pos,embeddings_initializer=label_init,trainable=False,dtype=tf.float32,name='pos_embeddings')\n",
    "        self.lab_embed = tf.keras.layers.Embedding(num_classes,num_classes,embeddings_initializer=label_init,trainable=False,dtype=tf.float32,name='label_embeddings')\n",
    "        self.encoder = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_hidden,return_sequences=True,return_state=True),name='lstm_enc')\n",
    "        self.postencoder = tf.keras.layers.Dense(2*lstm_hidden,activation='relu')\n",
    "        self.drop_postencoder = tf.keras.layers.Dropout(dropout)\n",
    "        self.attn_proj =  tf.keras.layers.Dense(2*lstm_hidden,use_bias=False,activation='relu')\n",
    "        self.context_proj = tf.keras.layers.Dense(lstm_hidden,use_bias=False,activation='tanh')\n",
    "        self.drop_context_proj = tf.keras.layers.Dropout(dropout)\n",
    "        self.out =  tf.keras.layers.Dense(num_classes)   #Use this for tensorflow < 2.4.0\n",
    "        \n",
    "#         self.softmax = tf.keras.layers.Softmax(axis=1) #Use this if already on tensorflow >= 2.4.0\n",
    "        self.softmax = Softmax(axis=1)\n",
    "    def call(self,x,training=False,mask_out=True):\n",
    "        x_enc = self.embed(x['input_ids'])\n",
    "        if self.use_pos:\n",
    "            x_pos = self.pos_embed(x['pos_tags'])\n",
    "            x_enc = tf.concat([x_enc,x_pos],axis=-1)\n",
    "        mask = x['attention_masks']\n",
    "        softmax_mask = tf.tile(mask[...,tf.newaxis],[1,1,tf.shape(x['attention_masks'])[1]])  \n",
    "        encoded = self.encoder(x_enc,mask=mask)\n",
    "        attn_proj = self.attn_proj(encoded[0]) \n",
    "        decoded = self.drop_postencoder(self.postencoder(x_enc))\n",
    "        e = tf.matmul(attn_proj,tf.transpose(decoded,perm=[0,2,1]))\n",
    "        alpha = tf.matmul(tf.transpose(encoded[0],perm=[0,2,1]),self.softmax(e,mask=softmax_mask))\n",
    "        context = tf.concat([tf.transpose(alpha,perm=[0,2,1]),decoded],axis=2)\n",
    "        o = self.drop_context_proj(self.context_proj(context))\n",
    "        out = self.out(o)  \n",
    "        if mask_out:\n",
    "            out._keras_mask = mask\n",
    "        return(out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and splitting the data\n",
    "**Loading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "a9daIhL9DbZx"
   },
   "outputs": [],
   "source": [
    "TRAINING_FILE = \"ner_dataset.csv\"\n",
    "sentences, pos, tag, enc_pos, enc_tag = process_data(TRAINING_FILE)\n",
    "label_array = enc_tag.classes_\n",
    "pos_array = enc_pos.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the data into different sets and building vocabulary to be used for encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "elxc7GNgDbZy",
    "outputId": "7020c38d-0312-4735-a8ed-a65a106b4c69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36688 4077 7194\n"
     ]
    }
   ],
   "source": [
    "train_test_split = 0.85\n",
    "train_val_split = 0.9\n",
    "\n",
    "train_sents = sentences[:int(train_test_split*len(sentences))]\n",
    "train_tags = tag[:int(train_test_split*len(tag))]\n",
    "train_pos = pos[:int(train_test_split*len(pos))]\n",
    "\n",
    "test_sents = sentences[int(train_test_split*len(sentences)):]\n",
    "test_tags = tag[int(train_test_split*len(tag)):]\n",
    "test_pos = pos[int(train_test_split*len(pos)):]\n",
    "\n",
    "val_sents = train_sents[int(train_val_split*len(train_sents)):]\n",
    "val_tags = train_tags[int(train_val_split*len(train_tags)):]\n",
    "val_pos = train_pos[int(train_val_split*len(train_pos)):]\n",
    "\n",
    "train_sents = train_sents[:int(train_val_split*len(train_sents))]\n",
    "train_tags = train_tags[:int(train_val_split*len(train_tags))]\n",
    "train_pos = train_pos[:int(train_val_split*len(train_pos))]\n",
    "\n",
    "cti,itc = build_char_vocab(train_sents,pad_index=0,pad_token=\"<PAD>\",unk_index=1,unk_token=\"<UNK>\")\n",
    "wti,itw = build_word_vocab(train_sents,pad_index=0,pad_token=\"<PAD>\",unk_index=1,unk_token=\"<UNK>\")\n",
    "print(len(train_sents),len(val_sents),len(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "**Defining training parameters and training the model using early stopping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Kq4f18FkDbZ3",
    "outputId": "2872622a-08be-42a2-e2de-44190969a805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training.....\n",
      "Epoch 1/10\n",
      "573/573 [==============================] - 913s 2s/step - loss: 0.1335 - accuracy: 0.9272 - val_loss: 0.0881 - val_accuracy: 0.9500\n",
      "Epoch 2/10\n",
      "573/573 [==============================] - 746s 1s/step - loss: 0.0746 - accuracy: 0.9562 - val_loss: 0.0623 - val_accuracy: 0.9614\n",
      "Epoch 3/10\n",
      "573/573 [==============================] - 751s 1s/step - loss: 0.0574 - accuracy: 0.9649 - val_loss: 0.0540 - val_accuracy: 0.9665\n",
      "Epoch 4/10\n",
      "573/573 [==============================] - 732s 1s/step - loss: 0.0523 - accuracy: 0.9675 - val_loss: 0.0521 - val_accuracy: 0.9680\n",
      "Epoch 5/10\n",
      "573/573 [==============================] - 723s 1s/step - loss: 0.0482 - accuracy: 0.9694 - val_loss: 0.0519 - val_accuracy: 0.9684\n",
      "Epoch 6/10\n",
      "573/573 [==============================] - 699s 1s/step - loss: 0.0455 - accuracy: 0.9706 - val_loss: 0.0488 - val_accuracy: 0.9690\n",
      "Epoch 7/10\n",
      "573/573 [==============================] - 753s 1s/step - loss: 0.0433 - accuracy: 0.9721 - val_loss: 0.0498 - val_accuracy: 0.9697\n",
      "Epoch 8/10\n",
      "573/573 [==============================] - 736s 1s/step - loss: 0.0411 - accuracy: 0.9733 - val_loss: 0.0499 - val_accuracy: 0.9693\n",
      "Epoch 9/10\n",
      "573/573 [==============================] - 704s 1s/step - loss: 0.0396 - accuracy: 0.9743 - val_loss: 0.0498 - val_accuracy: 0.9690\n",
      "Epoch 10/10\n",
      "573/573 [==============================] - 659s 1s/step - loss: 0.0365 - accuracy: 0.9761 - val_loss: 0.0495 - val_accuracy: 0.9699\n",
      "Finished Training !\n"
     ]
    }
   ],
   "source": [
    "use_char_level_model = True\n",
    "use_pos_features = True\n",
    "\n",
    "if use_char_level_model:\n",
    "    datagen = datagen_char\n",
    "    vocab = cti\n",
    "else:\n",
    "    datagen = datagen_word\n",
    "    vocab = wti\n",
    "    \n",
    "vocab_dim = len(vocab)\n",
    "batch_size = 64\n",
    "train_steps = int(len(train_sents)/batch_size)\n",
    "test_steps = int(len(test_sents)/batch_size)\n",
    "val_steps = int(len(val_sents)/batch_size)\n",
    "gen_train = datagen(train_sents,train_tags,train_pos,vocab,16,batch_size)\n",
    "gen_test = datagen(test_sents,test_tags,test_pos,vocab,16,batch_size)\n",
    "gen_val = datagen(val_sents,val_tags,val_pos,vocab,16,batch_size)\n",
    "\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "character_embedding_size = 256\n",
    "word_embedding_size = 256\n",
    "lstm_hidden_size = 256\n",
    "loss_func = masked_softmax_cross_entropy_loss\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=6,restore_best_weights=True)\n",
    "\n",
    "net =  BiLstm_attnv2(vocab_dim,\n",
    "                     character_embedding_size,\n",
    "                     word_embedding_size,\n",
    "                     lstm_hidden=lstm_hidden_size,\n",
    "                     num_classes=len(label_array),\n",
    "                     use_char_level_embeddings=use_char_level_model,\n",
    "                     dropout=0.3,\n",
    "                     use_pos_features=use_pos_features,\n",
    "                     num_pos=len(pos_array))\n",
    "\n",
    "net.compile(optimizer,loss_func,metrics=['accuracy'])\n",
    "\n",
    "print('Training.....')\n",
    "train_history = net.fit(gen_train,batch_size=batch_size,epochs=10,steps_per_  epoch=train_steps,\n",
    "        validation_data=gen_val,validation_steps=val_steps,callbacks=[callback],verbose=1)\n",
    "print('Finished Training !')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**Accuracy and Loss plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "history = train_history\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model\n",
    "**Running the model on test data and collecting all the true labels and predicted labels for the test data to be used for calculating metrics like accuracy, precision, recall and f1 score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Bb92Pve2DbZ8",
    "outputId": "5abf6a36-b2d8-4647-b351-61a4ea2b6c69"
   },
   "outputs": [],
   "source": [
    "#Test Loop\n",
    "i=0\n",
    "true = []\n",
    "pred = []\n",
    "for data in gen_test:            \n",
    "    x = data[0]\n",
    "    y = data[1]               \n",
    "    y_pred = net(x, training = False)  # Forward pass  \n",
    "    masked_pred = tf.boolean_mask(y_pred,y_pred._keras_mask)\n",
    "    masked_y = tf.boolean_mask(y,y_pred._keras_mask)\n",
    "    label_true = label_array[masked_y.numpy().astype(int)]\n",
    "    label_pred = label_array[np.argmax(masked_pred.numpy(),axis=-1).astype(int)]\n",
    "    true += label_true.tolist()\n",
    "    pred += label_pred.tolist()\n",
    "    i+=1\n",
    "    if i > test_steps:\n",
    "        break \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.33      0.03      0.06        59\n",
      "       B-eve       0.53      0.34      0.41        56\n",
      "       B-geo       0.85      0.91      0.88      5688\n",
      "       B-gpe       0.98      0.92      0.95      2557\n",
      "       B-nat       0.33      0.13      0.19        30\n",
      "       B-org       0.77      0.69      0.73      3006\n",
      "       B-per       0.81      0.82      0.81      2488\n",
      "       B-tim       0.93      0.86      0.89      3044\n",
      "       I-art       0.67      0.06      0.11        33\n",
      "       I-eve       0.48      0.28      0.35        39\n",
      "       I-geo       0.82      0.77      0.79      1145\n",
      "       I-gpe       0.73      0.26      0.38        31\n",
      "       I-nat       0.33      0.06      0.11        16\n",
      "       I-org       0.78      0.75      0.77      2424\n",
      "       I-per       0.82      0.90      0.86      2500\n",
      "       I-tim       0.78      0.68      0.73       941\n",
      "           O       0.99      0.99      0.99    132426\n",
      "\n",
      "    accuracy                           0.97    156483\n",
      "   macro avg       0.70      0.56      0.59    156483\n",
      "weighted avg       0.97      0.97      0.97    156483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn_cs(true,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fortunately, 'O' tags can be ignored, as they are predicted with almost perfect accuracy and we can remove them from the metrics. This helps us focus on the entities of interest and how our model performs for them. I will be using Seqeval library to calculate this based on Conlleval script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         art       0.25      0.03      0.06        59\n",
      "         eve       0.43      0.32      0.37        56\n",
      "         geo       0.82      0.89      0.86      5688\n",
      "         gpe       0.97      0.92      0.94      2557\n",
      "         nat       0.33      0.17      0.22        30\n",
      "         org       0.64      0.64      0.64      3006\n",
      "         per       0.69      0.74      0.71      2488\n",
      "         tim       0.85      0.83      0.84      3044\n",
      "\n",
      "   micro avg       0.79      0.81      0.80     16928\n",
      "   macro avg       0.62      0.57      0.58     16928\n",
      "weighted avg       0.79      0.81      0.80     16928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(seqeval_cs([true],[pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Above scores have humbled our expectations and shows the true prediction power of our model. True may be a very strong term as we have literally removed the majority class from the metrics.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random predictions\n",
    "**Lets see some randomly chosen predictions from the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "5dXYGFzlYBDa",
    "outputId": "8453b884-1fd9-480d-cc57-5f43a7148593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VOA', \"'s\", 'Chris', 'Simkins', 'reports', 'on', 'how', 'one', 'homeowner', 'in', '[', 'the', 'southern', 'US', 'state', 'of', ']', 'Virginia', 'is', 'fighting', 'to', 'keep', 'his', 'home', '.']\n",
      "['B-org' 'O' 'B-per' 'I-per' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'B-geo'\n",
      " 'O' 'O' 'O' 'B-geo' 'O' 'O' 'O' 'O' 'O' 'O' 'O']\n"
     ]
    }
   ],
   "source": [
    "# Randomly selects a sentence from the test data and displays the predictions\n",
    "index = np.random.randint(len(test_sents))\n",
    "statements = [test_sents[index]]\n",
    "pos = [test_pos[index]]\n",
    "x,y,mask,pos = to_padded_list_char(statements,cti,[],pos,0)\n",
    "x = np.array(x,dtype=np.float64)\n",
    "mask = np.array(mask)\n",
    "pos = np.array(pos)\n",
    "input_seq = {'input_ids': np.array(x,dtype=np.float64),\n",
    "             'attention_masks': np.array(mask),\n",
    "             'pos_tags': np.array(pos,dtype=np.float64)}\n",
    "labels = net(input_seq)\n",
    "\n",
    "for i in range(len(statements)):\n",
    "    print(statements[i])\n",
    "    print(label_array[np.argmax(labels[i],axis=-1)])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
